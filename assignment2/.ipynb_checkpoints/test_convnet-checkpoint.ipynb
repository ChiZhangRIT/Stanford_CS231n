{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from cs231n.classifiers.cnn import *\n",
    "from cs231n.data_utils import get_CIFAR10_data\n",
    "from cs231n.gradient_check import eval_numerical_gradient_array, eval_numerical_gradient\n",
    "from cs231n.layers import *\n",
    "from cs231n.fast_layers import *\n",
    "from cs231n.solver import Solver\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "def rel_error(x, y):\n",
    "  \"\"\" returns relative error \"\"\"\n",
    "  return np.max(np.abs(x - y) / (np.maximum(1e-8, np.abs(x) + np.abs(y))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_val:  (1000L, 3L, 32L, 32L)\n",
      "X_train:  (49000L, 3L, 32L, 32L)\n",
      "X_test:  (1000L, 3L, 32L, 32L)\n",
      "y_val:  (1000L,)\n",
      "y_train:  (49000L,)\n",
      "y_test:  (1000L,)\n"
     ]
    }
   ],
   "source": [
    "data = get_CIFAR10_data()\n",
    "for k, v in data.iteritems():\n",
    "  print '%s: ' % k, v.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional \"sandwich\" layers\n",
    "In the file `cs231n/layer_utils.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing conv_relu_conv_relu_pool\n",
      "dx error:  5.15920401734e-08\n",
      "dw1 error:  8.06346009126e-10\n",
      "db1 error:  1.02967828355e-09\n",
      "dw2 error:  4.32444890916e-10\n",
      "db2 error:  1.66922322994e-11\n"
     ]
    }
   ],
   "source": [
    "from cs231n.layer_utils import conv_relu_conv_relu_pool_forward, conv_relu_conv_relu_pool_backward\n",
    "\n",
    "x = np.random.randn(2, 3, 16, 16)\n",
    "w1 = np.random.randn(3, 3, 3, 3)\n",
    "b1 = np.random.randn(3,)\n",
    "w2 = np.random.randn(3, 3, 3, 3)\n",
    "b2 = np.random.randn(3,)\n",
    "dout = np.random.randn(2, 3, 8, 8)\n",
    "conv_param = {'stride': 1, 'pad': 1}\n",
    "pool_param = {'pool_height': 2, 'pool_width': 2, 'stride': 2}\n",
    "\n",
    "out, cache = conv_relu_conv_relu_pool_forward(x, w1, b1, w2, b2, conv_param, pool_param)\n",
    "dx, dw1, db1, dw2, db2 = conv_relu_conv_relu_pool_backward(dout, cache)\n",
    "\n",
    "dx_num = eval_numerical_gradient_array(lambda x: conv_relu_conv_relu_pool_forward(x, w1, b1, w2, b2, conv_param, pool_param)[0], x, dout)\n",
    "dw1_num = eval_numerical_gradient_array(lambda w1: conv_relu_conv_relu_pool_forward(x, w1, b1, w2, b2, conv_param, pool_param)[0], w1, dout)\n",
    "db1_num = eval_numerical_gradient_array(lambda b1: conv_relu_conv_relu_pool_forward(x, w1, b1, w2, b2, conv_param, pool_param)[0], b1, dout)\n",
    "dw2_num = eval_numerical_gradient_array(lambda w2: conv_relu_conv_relu_pool_forward(x, w1, b1, w2, b2, conv_param, pool_param)[0], w2, dout)\n",
    "db2_num = eval_numerical_gradient_array(lambda b2: conv_relu_conv_relu_pool_forward(x, w1, b1, w2, b2, conv_param, pool_param)[0], b2, dout)\n",
    "\n",
    "print 'Testing conv_relu_conv_relu_pool'\n",
    "print 'dx error: ', rel_error(dx_num, dx)\n",
    "print 'dw1 error: ', rel_error(dw1_num, dw1)\n",
    "print 'db1 error: ', rel_error(db1_num, db1)\n",
    "print 'dw2 error: ', rel_error(dw2_num, dw2)\n",
    "print 'db2 error: ', rel_error(db2_num, db2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity check loss\n",
    "After you build a new network, one of the first things you should do is sanity check the loss. When we use the softmax loss, we expect the loss for random weights (and no regularization) to be about `log(C)` for `C` classes. When we add regularization this should go up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing initialization ... \n",
      "parameters:  ['b11', 'W12', 'b21', 'b22', 'b12', 'W11', 'W21', 'W22', 'b_1', 'b_3', 'W_1', 'b_2', 'W_3', 'W_2']\n",
      "Initial scores shape: (50L, 10L) . Should be ( 50 , 10).\n",
      "Initial loss (no regularization):  2.30258509299 . Shoud be very close to 2.30258509299\n",
      "Initial loss (with regularization):  2.33802254583\n"
     ]
    }
   ],
   "source": [
    "fc_hidden_dims = [100, 50]\n",
    "num_filters = [64, 32, 32, 16]\n",
    "std = 1e-3\n",
    "model = ConvNet(fc_hidden_dims, num_filters, filter_size=3, stride=1, input_dim=(3, 32, 32),\n",
    "                 num_classes=10, use_batchnorm=False, dropout=0, weight_scale=std, reg=0.0,\n",
    "                 dtype=np.float32)\n",
    "\n",
    "print 'Testing initialization ... '\n",
    "W1_std = abs(model.params['W_1'].std() - std)\n",
    "b1 = model.params['b_1']\n",
    "W2_std = abs(model.params['W_2'].std() - std)\n",
    "b2 = model.params['b_2']\n",
    "W3_std = abs(model.params['W_3'].std() - std)\n",
    "b3 = model.params['b_3']\n",
    "W11_std = abs(model.params['W11'].std() - std)\n",
    "b11 = model.params['b11']\n",
    "W21_std = abs(model.params['W21'].std() - std)\n",
    "b21 = model.params['b21']\n",
    "W12_std = abs(model.params['W12'].std() - std)\n",
    "b12 = model.params['b12']\n",
    "W22_std = abs(model.params['W22'].std() - std)\n",
    "b22 = model.params['b22']\n",
    "\n",
    "print 'parameters: ', model.params.keys()\n",
    "\n",
    "assert W1_std < std / 10, 'First FC layer weights do not seem right'\n",
    "assert np.all(b1 == 0), 'First FC layer biases do not seem right'\n",
    "assert W2_std < std / 10, 'Second FC ayer weights do not seem right'\n",
    "assert np.all(b2 == 0), 'Second FC layer biases do not seem right'\n",
    "assert W3_std < std / 10, 'Third FC layer weights do not seem right'\n",
    "assert np.all(b3 == 0), 'Third FC layer biases do not seem right'\n",
    "assert W11_std < std / 10, 'First conv layer1 weights do not seem right'\n",
    "assert np.all(b11 == 0), 'First conv layer1 biases do not seem right'\n",
    "assert W21_std < std / 10, 'First conv layer2 weights do not seem right'\n",
    "assert np.all(b21 == 0), 'First conv layer2 biases do not seem right'\n",
    "assert W12_std < std / 10, 'Second conv layer1 weights do not seem right'\n",
    "assert np.all(b11 == 0), 'Second conv layer1 biases do not seem right'\n",
    "assert W22_std < std / 10, 'Second conv layer2 weights do not seem right'\n",
    "assert np.all(b21 == 0), 'Second conv layer2 biases do not seem right'\n",
    "\n",
    "N = 50\n",
    "X = np.random.randn(N, 3, 32, 32)\n",
    "y = np.random.randint(10, size=N)\n",
    "\n",
    "scores = model.loss(X)\n",
    "print 'Initial scores shape:', scores.shape, '. Should be (', N, ', 10).'\n",
    "\n",
    "loss, grads = model.loss(X, y)\n",
    "print 'Initial loss (no regularization): ', loss, '. Shoud be very close to', -np.log(1./10)\n",
    "\n",
    "model.reg = 0.5\n",
    "loss, grads = model.loss(X, y)\n",
    "print 'Initial loss (with regularization): ', loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient check\n",
    "After the loss looks reasonable, use numeric gradient checking to make sure that your backward pass is correct. When you use numeric gradient checking you should use a small amount of artifical data and a small number of neurons at each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W11 max relative error: 2.250286e-03\n",
      "W12 max relative error: 5.115137e-02\n",
      "W21 max relative error: 1.172350e-01\n",
      "W22 max relative error: 1.648105e-03\n",
      "W_1 max relative error: 2.939754e-03\n",
      "W_2 max relative error: 1.068133e-03\n",
      "W_3 max relative error: 1.000000e+00\n",
      "b11 max relative error: 5.323990e-03\n",
      "b12 max relative error: 5.918992e-05\n",
      "b21 max relative error: 7.541519e-05\n",
      "b22 max relative error: 3.177540e-05\n",
      "b_1 max relative error: 3.911402e-04\n",
      "b_2 max relative error: 1.026653e-05\n",
      "b_3 max relative error: 1.550175e-06\n"
     ]
    }
   ],
   "source": [
    "fc_hidden_dims = [50, 20]\n",
    "num_filters = [32, 16, 16, 8]\n",
    "std = 0.1\n",
    "\n",
    "num_inputs = 2\n",
    "input_dim = (3, 16, 16)\n",
    "reg = 0.0\n",
    "num_classes = 10\n",
    "\n",
    "X = np.random.randn(num_inputs, *input_dim)\n",
    "y = np.random.randint(num_classes, size=num_inputs)\n",
    "\n",
    "model = ConvNet(fc_hidden_dims, num_filters, filter_size=3, stride=1, input_dim=input_dim,\n",
    "                 num_classes=10, use_batchnorm=False, dropout=0, weight_scale=std, reg=0.5,\n",
    "                 dtype=np.float64)\n",
    "loss, grads = model.loss(X, y)\n",
    "for param_name in sorted(grads):\n",
    "    f = lambda _: model.loss(X, y)[0]\n",
    "    param_grad_num = eval_numerical_gradient(f, model.params[param_name], verbose=False, h=1e-8)\n",
    "    e = rel_error(param_grad_num, grads[param_name])\n",
    "    print '%s max relative error: %e' % (param_name, rel_error(param_grad_num, grads[param_name]))\n",
    "#     print param_grad_num.shape, param_grad_num\n",
    "#     print grads[param_name].shape, grads[param_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overfit small data\n",
    "A nice trick is to train your model with just a few training samples. You should be able to overfit small datasets, which will result in very high training accuracy and comparatively low validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (50,512) and (128,50) not aligned: 512 (dim 1) != 128 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-c85d7f52dc00>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     22\u001b[0m                 },\n\u001b[0;32m     23\u001b[0m                 verbose=True, print_every=1)\n\u001b[1;32m---> 24\u001b[1;33m \u001b[0msolver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\10189461\\dropbox\\imaging science\\stanford university cs231n - cnn for visual recognition\\assignments\\assignment2\\cs231n\\solver.pyc\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    233\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_iterations\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 235\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# make a single gradient update for each parameter\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    236\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m             \u001b[1;31m# Maybe print training loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\10189461\\dropbox\\imaging science\\stanford university cs231n - cnn for visual recognition\\assignments\\assignment2\\cs231n\\solver.pyc\u001b[0m in \u001b[0;36m_step\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m         \u001b[1;31m# Compute loss and gradient\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 163\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    164\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss_history\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\10189461\\dropbox\\imaging science\\stanford university cs231n - cnn for visual recognition\\assignments\\assignment2\\cs231n\\classifiers\\cnn.pyc\u001b[0m in \u001b[0;36mloss\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    241\u001b[0m             \u001b[0mW\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'W_'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m             \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'b_'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 243\u001b[1;33m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'fc'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maffine_relu_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    244\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    245\u001b[0m         \u001b[0mW\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'W_'\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc_dims\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\10189461\\dropbox\\imaging science\\stanford university cs231n - cnn for visual recognition\\assignments\\assignment2\\cs231n\\layer_utils.pyc\u001b[0m in \u001b[0;36maffine_relu_forward\u001b[1;34m(x, w, b)\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;33m-\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mObject\u001b[0m \u001b[0mto\u001b[0m \u001b[0mgive\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mbackward\u001b[0m \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \"\"\"\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfc_cache\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maffine_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m     \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrelu_cache\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrelu_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mcache\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfc_cache\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrelu_cache\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\10189461\\dropbox\\imaging science\\stanford university cs231n - cnn for visual recognition\\assignments\\assignment2\\cs231n\\layers.pyc\u001b[0m in \u001b[0;36maffine_forward\u001b[1;34m(x, w, b)\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;31m# will need to reshape the input into rows.                                 #\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[1;31m#############################################################################\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m     \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mb\u001b[0m  \u001b[1;31m# shape (N, M)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m     \u001b[1;31m#############################################################################\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;31m#                             END OF YOUR CODE                              #\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (50,512) and (128,50) not aligned: 512 (dim 1) != 128 (dim 0)"
     ]
    }
   ],
   "source": [
    "num_train = 100\n",
    "small_data = {\n",
    "  'X_train': data['X_train'][:num_train],\n",
    "  'y_train': data['y_train'][:num_train],\n",
    "  'X_val': data['X_val'],\n",
    "  'y_val': data['y_val'],\n",
    "}\n",
    "\n",
    "fc_hidden_dims = [50, 20]\n",
    "num_filters = [32, 16, 16, 8]\n",
    "input_dim = (3, 16, 16)\n",
    "\n",
    "model = ConvNet(fc_hidden_dims, num_filters, filter_size=3, stride=1, input_dim=input_dim,\n",
    "                 num_classes=10, use_batchnorm=False, dropout=0, weight_scale=1e-1, reg=0.5,\n",
    "                 dtype=np.float64)\n",
    "\n",
    "solver = Solver(model, small_data,\n",
    "                num_epochs=10, batch_size=50,\n",
    "                update_rule='adam',\n",
    "                optim_config={\n",
    "                  'learning_rate': 1e-3,\n",
    "                },\n",
    "                verbose=True, print_every=1)\n",
    "solver.train()\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(solver.loss_history, 'o')\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('loss')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(solver.train_acc_history, '-o')\n",
    "plt.plot(solver.val_acc_history, '-o')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
